{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m2gSP60pfxKI"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers, activations, models, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W5W7LoqfgqZV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import preprocessing, utils\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rZik1RqfrHdj"
   },
   "outputs": [],
   "source": [
    "dir_path = r'C:\\Users\\HP\\Downloads\\Chatbot\\Chatbot\\Data'\n",
    "files_list = os.listdir(dir_path + os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0I3F935wrBEy",
    "outputId": "12eb918b-f683-458c-b32d-3efcb9e6c3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 1894\n"
     ]
    }
   ],
   "source": [
    "questions = list()\n",
    "answers = list()\n",
    "\n",
    "for filepath in files_list:\n",
    "  if filepath !='.ipynb_checkpoints':\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)\n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[ 1 : ]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append( ans )\n",
    "        elif len( con )> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6UW3jQZys7Pw"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XoKdC-Ups_wu"
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "  vocab.append(word)\n",
    "\n",
    "def tokenize(sentences):\n",
    "  tokens_list = []\n",
    "  vocabulary = []\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    tokens = sentence.split()\n",
    "    vocabulary += tokens\n",
    "    tokens_list.append(tokens)\n",
    "  return tokens_list, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvipgtsxtCHw",
    "outputId": "10cdf48d-fbd9-41c5-b879-6b596bfe9542",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 22) 22\n"
     ]
    }
   ],
   "source": [
    "#encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print(encoder_input_data.shape, maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YV2nV9NjtEXT",
    "outputId": "f4d1a4b6-d913-4c1d-b4f9-b7773bb7b1fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74) 74\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmFZKUiJtGuP",
    "outputId": "c08965c5-f832-4227-c703-6c25e3e2d0d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74, 1894)\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfNqA0YytJH1",
    "outputId": "71f84273-05d2-4e62-fd76-05d6b777f041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 74)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 22, 200)      378800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 74, 200)      378800      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 74, 200),    320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 74, 1894)     380694      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,779,894\n",
      "Trainable params: 1,779,894\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaAtN16ftLBE",
    "outputId": "13de0952-a38e-414a-ff1f-42bb4d060300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 13s 276ms/step - loss: 7.5248\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 6.7197\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 5.9758\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 5.8378\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 5.7821\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 5.7416\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 5.7219\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 5.7052\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 5.6754\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 5.6445\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 5.6232\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 5.5787\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 5.5366\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 5.4942\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 5.4488\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 5.4141\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 5.3869\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 5.3600\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 5.3345\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 5.3188\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 5.2989\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 5.2838\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 5.2672\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 5.2459\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 4s 312ms/step - loss: 5.2288\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 4s 312ms/step - loss: 5.2147\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 5.1945\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 5.1747\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 5.1459\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 4s 319ms/step - loss: 5.1285\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 5.1043\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 5.0727\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 4s 319ms/step - loss: 5.0623\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 5.0232\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 5.0259\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 5.0005\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 4.9777\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 4.9509\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 4.9333\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 4.9118\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 4.8846\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 4s 312ms/step - loss: 4.8699\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 4.8510\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 4.8208\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 4.8059\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 4.7781\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 4.7609\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 4.7378\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 4.7314\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 4.6952\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 4.6863\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 4.6571\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 4.6359\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 4.6147\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 4.5975\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 4.5750\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 4.5536\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 4.5319\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 4.5031\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 4.4940\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 4.4754\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 4.4469\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 4.4277\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 4.4105\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 4.3826\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 4.3569\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 4.3506\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 4.3311\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 4.3073\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 4.2778\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 4.2650\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 4.2520\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 4.2239\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 4.2095\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 4.1771\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 4.1721\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 4.1522\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 4.1421\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 4.1177\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 4.1039\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 4.0688\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 4.0638\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 4.0300\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 4.0244\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 3.9993\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3.9778\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3.9596\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 3.9373\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3.9228\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 3.9046\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 3.8887\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3.8723\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 3.8307\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 3.8383\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 3.8143\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 3.7872\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 3.7759\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 3.7604\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 3.7369\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 3.7192\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 3.7057\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 3.6857\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 3.6682\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 3.6647\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 3.6393\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3.6226\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 3.6056\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3.5844\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3.5732\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 3.5487\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 3.5306\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 3.5208\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 3.5038\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 3.4768\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 3.4601\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 3.4550\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 3.4386\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 3.4149\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 3.4077\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 3.3916\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 3.3816\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 3.3483\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 3.3374\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 3.3330\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 3.3175\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 3.2780\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 3.2496\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 3.2629\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 3.2470\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 3.2164\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 3.2120\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 3.1947\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 3.1724\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 3.1668\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 3.1578\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 3.1420\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 3.1108\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 3.0996\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 3.0844\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 3.0802\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 3.0625\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 3.0598\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 3.0337\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 3.0184\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 2.9942\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2.9869\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 2.9654\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 2.9585\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 2.9376\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2.9307\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 2.9137\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 2.8933\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 2.8769\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 2.8667\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 2.8538\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 2.8454\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.8313\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 2.8133\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 2.8045\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 2.7795\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.7710\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 2.7519\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 2.7471\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 2.7232\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.7211\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.6974\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 2.6867\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 2.6679\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 2.6569\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 2.6477\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 2.6330\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 2.6062\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 2.6031\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 2.5830\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 2.5772\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 2.5628\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 2.5521\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.5280\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.5132\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 2.5090\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 2.4985\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.4726\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.4680\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.4550\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.4477\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.4228\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 2.4118\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.4070\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 2.3959\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.3788\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 2.3634\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 2.3532\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 2.3430\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 2.3308\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 2.3177\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.3026\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 2.2853\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 2.2814\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 2.2591\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 2.2415\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.2403\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.2319\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.2128\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 2.1951\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 2.1836\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 2.1671\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 2.1675\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 2.1538\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.1412\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 2.1241\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 2.1158\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 2.0997\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 2.0904\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.0842\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 2.0694\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 2.0547\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 2.0384\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.0415\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 2.0074\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 2.0087\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 3s 270ms/step - loss: 1.9947\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 1.9874\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.9696\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.9633\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 1.9581\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.9394\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.9242\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 1.9173\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.9078\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 1.8921\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 1.8925\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.8718\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.8626\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 1.8571\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.8381\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.8295\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 1.8164\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.8104\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 3s 267ms/step - loss: 1.8010\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 3s 263ms/step - loss: 1.7842\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 1.7734\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.7685\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 3s 267ms/step - loss: 1.7544\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 3s 270ms/step - loss: 1.7411\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.7324\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.7190\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 3s 270ms/step - loss: 1.7110\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.7048\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.6909\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.6822\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.6702\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 1.6726\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 1.6458\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.6380\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 1.6342\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 1.6160\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 1.6109\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.5956\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.5875\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.5786\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 1.5685\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 3s 270ms/step - loss: 1.5599\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 3s 261ms/step - loss: 1.5484\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.5410\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 1.5328\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.5237\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.5100\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 1.5045\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.4971\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.4817\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.4758\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.4637\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 1.4549\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 1.4437\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 1.4296\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.4283\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.4248\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 1.4099\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 1.4002\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 1.4002\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.3799\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.3712\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 1.3704\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.3591\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 1.3442\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.3424\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.3303\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 1.3236\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.3077\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 1.3101\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 1.2957\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.2867\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.2818\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 1.2701\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.2638\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.2506\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.2429\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.2377\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 1.2309\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.2200\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.2105\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.1959\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 1.2012\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 1.1934\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.1813\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 1.1686\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 1.1718\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 3s 270ms/step - loss: 1.1549\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 1.1498\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 1.1506\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.1319\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 1.1405\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 1.1169\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.1113\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 1.1071\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 1.0948\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 1.0971\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 1.0824\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 1.0657\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 1.0715\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 1.0667\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 1.0538\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 1.0363\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.0453\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 1.0318\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 1.0233\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 1.0162\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 1.0072\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 1.0048\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.9940\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 1.0002\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 0.9841\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 0.9718\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.9741\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 0.9683\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.9631\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.9650\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.9430\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.9405\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.9249\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.9258\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.9210\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.9156\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.9035\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.8972\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.8930\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 0.8882\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.8787\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.8716\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.8688\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 0.8672\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.8568\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.8548\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.8413\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.8388\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.8305\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.8217\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.8224\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.8147\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.8071\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.8036\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 0.8013\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.7939\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.7842\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 0.7844\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.7748\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.7714\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 0.7629\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.7610\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 0.7553\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 0.7455\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.7409\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.7503\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.7361\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.7256\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.7223\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.7184\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.7116\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 3s 277ms/step - loss: 0.7080\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.6950\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.6942\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.6925\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.6819\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.6777\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.6721\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.6740\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.6662\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 0.6832\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.6556\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.6528\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.6494\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.6442\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 0.6381\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 3s 288ms/step - loss: 0.6335\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 0.6318\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 0.6238\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.6204\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.6150\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.6139\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.6044\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 0.6029\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.5995\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 0.5946\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 0.5877\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.5837\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.5836\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.5731\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.5730\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.5657\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.5660\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 0.5582\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.5629\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 0.5507\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.5450\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 0.5463\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.5374\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.5332\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.5348\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.5342\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.5240\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.5155\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.5142\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.5138\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.5042\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.5081\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 0.5025\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.5018\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.4905\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 0.4881\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.4901\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.4884\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.4786\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.4783\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 0.4777\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 0.4658\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.4693\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.4634\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 0.4606\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 0.4608\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 0.4558\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.4510\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.4485\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.4400\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 0.4419\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.4379\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.4307\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.4323\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.4302\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.4254\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.4200\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.4224\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 0.4114\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.4205\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.4115\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.4141\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.4059\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.4032\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.3974\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.3961\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.4058\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.3882\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.3866\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.3824\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.4030\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 0.3767\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 0.3769\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 0.3731\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.3727\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.3809\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 0.3668\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.3623\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.3601\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.3574\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.3606\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 0.3532\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.3520\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.3489\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.3517\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.3465\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 0.3392\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.3382\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.3414\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.3351\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.3342\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.3392\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 0.3277\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.3252\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.3263\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.3216\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.3185\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.3192\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 0.3189\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 0.3168\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.3085\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.3105\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 0.3080\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 0.3078\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 0.3019\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.3007\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=500 ) \n",
    "model.save( 'model.h1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-uL3sFb2tyT_"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DvS7mj6Rtzln"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "  \n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5fqgSA0BuhXu",
    "outputId": "2f8eab13-9755-49b7-d5a3-fa381f3eb039"
   },
   "outputs": [],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ]\n",
    "\n",
    "    print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
